{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65754f43-e247-4833-992f-7aba84761416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 00:01:01,026\tINFO worker.py:1819 -- Started a local Ray instance.\n",
      "2025-01-02 00:01:06,545\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-01-02 00:01:06 (running for 00:00:00.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-01-06/TorchTrainer_2025-01-02_00-01-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:01:12 (running for 00:00:05.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-01-06/TorchTrainer_2025-01-02_00-01-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:01:17 (running for 00:00:10.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-01-06/TorchTrainer_2025-01-02_00-01-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:01:22 (running for 00:00:15.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-01-06/TorchTrainer_2025-01-02_00-01-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:01:27 (running for 00:00:20.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-01-06/TorchTrainer_2025-01-02_00-01-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:01:32 (running for 00:00:25.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-01-06/TorchTrainer_2025-01-02_00-01-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:01:37 (running for 00:00:30.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-01-06/TorchTrainer_2025-01-02_00-01-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=8096)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "2025-01-02 00:01:42,210\tERROR tune_controller.py:1331 -- Trial task failed for trial TorchTrainer_c13cb_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_Inner.train()\u001b[39m (pid=7656, ip=127.0.0.1, actor_id=06b6c0614a2cc7e282a9034201000000, repr=TorchTrainer)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\air\\_internal\\util.py\", line 104, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py\", line 799, in _trainable_func\n",
      "    super()._trainable_func(self._merged_config)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py\", line 107, in _train_coordinator_fn\n",
      "    trainer.training_loop()\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\data_parallel_trainer.py\", line 459, in training_loop\n",
      "    backend_executor.start()\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\backend_executor.py\", line 203, in start\n",
      "    self._backend.on_start(self.worker_group, self._backend_config)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\torch\\config.py\", line 200, in on_start\n",
      "    ray.get(setup_futures)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_RayTrainWorker__execute._setup_torch_process_group()\u001b[39m (pid=8096, ip=127.0.0.1, actor_id=7d005dc4ccb1940f07c70fab01000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x0000023D10A77110>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\worker_group.py\", line 33, in __execute\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\worker_group.py\", line 30, in __execute\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\torch\\config.py\", line 115, in _setup_torch_process_group\n",
      "    dist.init_process_group(\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 83, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 97, in wrapper\n",
      "    func_return = func(*args, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1520, in init_process_group\n",
      "    store, rank, world_size = next(rendezvous_iterator)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 269, in _env_rendezvous_handler\n",
      "    store = _create_c10d_store(\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 189, in _create_c10d_store\n",
      "    return TCPStore(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: use_libuv was requested but PyTorch was build without libuv support\n",
      "2025-01-02 00:01:42,265\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/white/ray_results/TorchTrainer_2025-01-02_00-01-06' in 0.0194s.\n",
      "2025-01-02 00:01:42,274\tERROR tune.py:1037 -- Trials did not complete: [TorchTrainer_c13cb_00000]\n",
      "2025-01-02 00:01:42,275\tINFO tune.py:1041 -- Total run time: 35.73 seconds (35.60 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-01-02 00:01:42 (running for 00:00:35.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-01-06/TorchTrainer_2025-01-02_00-01-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 ERROR)\n",
      "Number of errored trials: 1\n",
      "+--------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name               |   # failures | error file                                                                                                                                                                                                             |\n",
      "|--------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| TorchTrainer_c13cb_00000 |            1 | C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-01-06/TorchTrainer_2025-01-02_00-01-06/driver_artifacts/TorchTrainer_c13cb_00000_0_2025-01-02_00-01-06/error.txt |\n",
      "+--------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "TrainingFailedError",
     "evalue": "The Ray Train run failed. Please inspect the previous error messages for a cause. After fixing the issue (assuming that the error is not caused by your own application logic, but rather an error such as OOM), you can restart the run from scratch or continue this run.\nTo continue this run, you can use: `trainer = TorchTrainer.restore(\"C:/Users/white/ray_results/TorchTrainer_2025-01-02_00-01-06\")`.\nTo start a new run that will retry on training failures, set `train.RunConfig(failure_config=train.FailureConfig(max_failures))` in the Trainer's `run_config` with `max_failures > 0`, or `max_failures = -1` for unlimited retries.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRayTaskError(RuntimeError)\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;31mRayTaskError(RuntimeError)\u001b[0m: \u001b[36mray::_Inner.train()\u001b[39m (pid=7656, ip=127.0.0.1, actor_id=06b6c0614a2cc7e282a9034201000000, repr=TorchTrainer)\n  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n    raise skipped from exception_cause(skipped)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\air\\_internal\\util.py\", line 104, in run\n    self._ret = self._target(*self._args, **self._kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n    training_func=lambda: self._trainable_func(self.config),\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py\", line 799, in _trainable_func\n    super()._trainable_func(self._merged_config)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 250, in _trainable_func\n    output = fn()\n             ^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py\", line 107, in _train_coordinator_fn\n    trainer.training_loop()\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\data_parallel_trainer.py\", line 459, in training_loop\n    backend_executor.start()\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\backend_executor.py\", line 203, in start\n    self._backend.on_start(self.worker_group, self._backend_config)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\torch\\config.py\", line 200, in on_start\n    ray.get(setup_futures)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_RayTrainWorker__execute._setup_torch_process_group()\u001b[39m (pid=8096, ip=127.0.0.1, actor_id=7d005dc4ccb1940f07c70fab01000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x0000023D10A77110>)\n  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\worker_group.py\", line 33, in __execute\n    raise skipped from exception_cause(skipped)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\worker_group.py\", line 30, in __execute\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\torch\\config.py\", line 115, in _setup_torch_process_group\n    dist.init_process_group(\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 83, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 97, in wrapper\n    func_return = func(*args, **kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1520, in init_process_group\n    store, rank, world_size = next(rendezvous_iterator)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 269, in _env_rendezvous_handler\n    store = _create_c10d_store(\n            ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 189, in _create_c10d_store\n    return TCPStore(\n           ^^^^^^^^^\nRuntimeError: use_libuv was requested but PyTorch was build without libuv support",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTrainingFailedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 69\u001b[0m\n\u001b[0;32m     62\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TorchTrainer(\n\u001b[0;32m     63\u001b[0m     train_loop_per_worker\u001b[38;5;241m=\u001b[39mtrain_fn,\n\u001b[0;32m     64\u001b[0m     scaling_config\u001b[38;5;241m=\u001b[39mScalingConfig(num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     65\u001b[0m     train_loop_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: size}\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Train and get results\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     72\u001b[0m end_memory \u001b[38;5;241m=\u001b[39m psutil\u001b[38;5;241m.\u001b[39mProcess()\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss  \u001b[38;5;66;03m# Track memory after training\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py:638\u001b[0m, in \u001b[0;36mBaseTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m result \u001b[38;5;241m=\u001b[39m result_grid[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39merror:\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;66;03m# Raise trainable errors to the user with a message to restore\u001b[39;00m\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;66;03m# or configure `FailureConfig` in a new run.\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TrainingFailedError(\n\u001b[0;32m    639\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([restore_msg, TrainingFailedError\u001b[38;5;241m.\u001b[39m_FAILURE_CONFIG_MSG])\n\u001b[0;32m    640\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mresult\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merror\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mTrainingFailedError\u001b[0m: The Ray Train run failed. Please inspect the previous error messages for a cause. After fixing the issue (assuming that the error is not caused by your own application logic, but rather an error such as OOM), you can restart the run from scratch or continue this run.\nTo continue this run, you can use: `trainer = TorchTrainer.restore(\"C:/Users/white/ray_results/TorchTrainer_2025-01-02_00-01-06\")`.\nTo start a new run that will retry on training failures, set `train.RunConfig(failure_config=train.FailureConfig(max_failures))` in the Trainer's `run_config` with `max_failures > 0`, or `max_failures = -1` for unlimited retries."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ray\n",
    "import psutil\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air import ScalingConfig\n",
    "\n",
    "# Initialize Ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# Define the training function\n",
    "@ray.remote\n",
    "def train_fn(config):\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "    # Simulate data size\n",
    "    data_size = config[\"data_size\"]\n",
    "    batch_size = config.get(\"batch_size\", 64)\n",
    "\n",
    "    # Generate synthetic data (X: features, y: labels)\n",
    "    X = torch.randn(data_size, 10)  # 10 features\n",
    "    y = torch.randint(0, 2, (data_size,))\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(10, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 2)  # Output layer for 2 classes\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training loop (1 epoch for faster execution)\n",
    "    epochs = 2\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return {\"final_loss\": total_loss}\n",
    "\n",
    "# Dataset sizes for testing scalability (smaller size for quicker testing)\n",
    "datasets = [1_000]  # Starting with a smaller dataset size for faster execution\n",
    "\n",
    "# Loop through datasets and train\n",
    "for size in datasets:\n",
    "    start_time = time.time()\n",
    "    start_memory = psutil.Process().memory_info().rss  # Track memory before training\n",
    "    \n",
    "    # Configure the trainer (Using fewer workers, num_workers=1)\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=train_fn,\n",
    "        scaling_config=ScalingConfig(num_workers=1),\n",
    "        train_loop_config={\"data_size\": size}\n",
    "    )\n",
    "\n",
    "    # Train and get results\n",
    "    results = trainer.fit()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    end_memory = psutil.Process().memory_info().rss  # Track memory after training\n",
    "    \n",
    "    training_time = end_time - start_time\n",
    "    memory_usage = (end_memory - start_memory) / (1024 ** 2)  # Convert to MB\n",
    "    \n",
    "    print(f\"Dataset size: {size}, Training time: {training_time:.2f} seconds, Memory usage: {memory_usage:.2f} MB\")\n",
    "\n",
    "# Shut down Ray\n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db69970-2b1a-4994-ab6b-e0366585202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7fe8bd2-d528-4f32-bca7-8ad39877adde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Untitled2.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f6e704e-a180-4a84-bb35-1ceae2ec689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\tmodified:   Untitled2.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "053c7bdc-f8c9-4137-8180-c4e5d744e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global core.autocrlf true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7035198-1358-4c70-bfd8-c81a224ceac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae8a01fc-2c3b-48ee-8601-6f0a9f8b2b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\tmodified:   Untitled2.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48587b4d-5b65-4e9b-b777-204840002c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   Untitled2.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3487222-2e81-4838-b1ef-c46ba2eafad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git commit -m \"Updated training with more memory usage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8b3c1-3057-4a01-9666-9716b2f8f2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
