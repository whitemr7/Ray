{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65754f43-e247-4833-992f-7aba84761416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 00:34:29,224\tINFO worker.py:1652 -- Calling ray.init() again after it has already been called.\n",
      "2025-01-02 00:34:29,445\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-01-02 00:34:29 (running for 00:00:00.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-34-29/TorchTrainer_2025-01-02_00-34-29/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:34:34 (running for 00:00:05.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-34-29/TorchTrainer_2025-01-02_00-34-29/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:34:39 (running for 00:00:10.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-34-29/TorchTrainer_2025-01-02_00-34-29/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:34:44 (running for 00:00:15.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-34-29/TorchTrainer_2025-01-02_00-34-29/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-01-02 00:34:49 (running for 00:00:20.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-34-29/TorchTrainer_2025-01-02_00-34-29/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 00:34:53,471\tERROR tune_controller.py:1331 -- Trial task failed for trial TorchTrainer_6b0ec_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_Inner.train()\u001b[39m (pid=13348, ip=127.0.0.1, actor_id=e0c8802f534b00c49da88bf001000000, repr=TorchTrainer)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\air\\_internal\\util.py\", line 104, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py\", line 799, in _trainable_func\n",
      "    super()._trainable_func(self._merged_config)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py\", line 107, in _train_coordinator_fn\n",
      "    trainer.training_loop()\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\data_parallel_trainer.py\", line 459, in training_loop\n",
      "    backend_executor.start()\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\backend_executor.py\", line 203, in start\n",
      "    self._backend.on_start(self.worker_group, self._backend_config)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\torch\\config.py\", line 200, in on_start\n",
      "    ray.get(setup_futures)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_RayTrainWorker__execute._setup_torch_process_group()\u001b[39m (pid=13932, ip=127.0.0.1, actor_id=ea1534ddf814c84e10e5a34201000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x0000021980D46C90>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\worker_group.py\", line 33, in __execute\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\worker_group.py\", line 30, in __execute\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\torch\\config.py\", line 115, in _setup_torch_process_group\n",
      "    dist.init_process_group(\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 83, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 97, in wrapper\n",
      "    func_return = func(*args, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1520, in init_process_group\n",
      "    store, rank, world_size = next(rendezvous_iterator)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 269, in _env_rendezvous_handler\n",
      "    store = _create_c10d_store(\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 189, in _create_c10d_store\n",
      "    return TCPStore(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: use_libuv was requested but PyTorch was build without libuv support\n",
      "2025-01-02 00:34:53,534\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/white/ray_results/TorchTrainer_2025-01-02_00-34-29' in 0.0205s.\n",
      "2025-01-02 00:34:53,558\tERROR tune.py:1037 -- Trials did not complete: [TorchTrainer_6b0ec_00000]\n",
      "2025-01-02 00:34:53,564\tINFO tune.py:1041 -- Total run time: 24.12 seconds (24.04 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-01-02 00:34:53 (running for 00:00:24.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-34-29/TorchTrainer_2025-01-02_00-34-29/driver_artifacts\n",
      "Number of trials: 1/1 (1 ERROR)\n",
      "Number of errored trials: 1\n",
      "+--------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name               |   # failures | error file                                                                                                                                                                                                             |\n",
      "|--------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| TorchTrainer_6b0ec_00000 |            1 | C:/Users/white/AppData/Local/Temp/ray/session_2025-01-02_00-00-56_174621_6956/artifacts/2025-01-02_00-34-29/TorchTrainer_2025-01-02_00-34-29/driver_artifacts/TorchTrainer_6b0ec_00000_0_2025-01-02_00-34-29/error.txt |\n",
      "+--------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "TrainingFailedError",
     "evalue": "The Ray Train run failed. Please inspect the previous error messages for a cause. After fixing the issue (assuming that the error is not caused by your own application logic, but rather an error such as OOM), you can restart the run from scratch or continue this run.\nTo continue this run, you can use: `trainer = TorchTrainer.restore(\"C:/Users/white/ray_results/TorchTrainer_2025-01-02_00-34-29\")`.\nTo start a new run that will retry on training failures, set `train.RunConfig(failure_config=train.FailureConfig(max_failures))` in the Trainer's `run_config` with `max_failures > 0`, or `max_failures = -1` for unlimited retries.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRayTaskError(RuntimeError)\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;31mRayTaskError(RuntimeError)\u001b[0m: \u001b[36mray::_Inner.train()\u001b[39m (pid=13348, ip=127.0.0.1, actor_id=e0c8802f534b00c49da88bf001000000, repr=TorchTrainer)\n  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n    raise skipped from exception_cause(skipped)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\air\\_internal\\util.py\", line 104, in run\n    self._ret = self._target(*self._args, **self._kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n    training_func=lambda: self._trainable_func(self.config),\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py\", line 799, in _trainable_func\n    super()._trainable_func(self._merged_config)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 250, in _trainable_func\n    output = fn()\n             ^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py\", line 107, in _train_coordinator_fn\n    trainer.training_loop()\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\data_parallel_trainer.py\", line 459, in training_loop\n    backend_executor.start()\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\backend_executor.py\", line 203, in start\n    self._backend.on_start(self.worker_group, self._backend_config)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\torch\\config.py\", line 200, in on_start\n    ray.get(setup_futures)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_RayTrainWorker__execute._setup_torch_process_group()\u001b[39m (pid=13932, ip=127.0.0.1, actor_id=ea1534ddf814c84e10e5a34201000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x0000021980D46C90>)\n  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 1803, in ray._raylet.execute_task.function_executor\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\worker_group.py\", line 33, in __execute\n    raise skipped from exception_cause(skipped)\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\_internal\\worker_group.py\", line 30, in __execute\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\torch\\config.py\", line 115, in _setup_torch_process_group\n    dist.init_process_group(\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 83, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 97, in wrapper\n    func_return = func(*args, **kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1520, in init_process_group\n    store, rank, world_size = next(rendezvous_iterator)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 269, in _env_rendezvous_handler\n    store = _create_c10d_store(\n            ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 189, in _create_c10d_store\n    return TCPStore(\n           ^^^^^^^^^\nRuntimeError: use_libuv was requested but PyTorch was build without libuv support",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTrainingFailedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 73\u001b[0m\n\u001b[0;32m     66\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TorchTrainer(\n\u001b[0;32m     67\u001b[0m     train_loop_per_worker\u001b[38;5;241m=\u001b[39mtrain_fn,\n\u001b[0;32m     68\u001b[0m     scaling_config\u001b[38;5;241m=\u001b[39mScalingConfig(num_workers\u001b[38;5;241m=\u001b[39mnum_workers),\n\u001b[0;32m     69\u001b[0m     train_loop_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: size}\n\u001b[0;32m     70\u001b[0m )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Train and get results\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     76\u001b[0m end_memory \u001b[38;5;241m=\u001b[39m psutil\u001b[38;5;241m.\u001b[39mProcess()\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss  \u001b[38;5;66;03m# Track memory after training\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\train\\base_trainer.py:638\u001b[0m, in \u001b[0;36mBaseTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m result \u001b[38;5;241m=\u001b[39m result_grid[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39merror:\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;66;03m# Raise trainable errors to the user with a message to restore\u001b[39;00m\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;66;03m# or configure `FailureConfig` in a new run.\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TrainingFailedError(\n\u001b[0;32m    639\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([restore_msg, TrainingFailedError\u001b[38;5;241m.\u001b[39m_FAILURE_CONFIG_MSG])\n\u001b[0;32m    640\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mresult\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merror\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mTrainingFailedError\u001b[0m: The Ray Train run failed. Please inspect the previous error messages for a cause. After fixing the issue (assuming that the error is not caused by your own application logic, but rather an error such as OOM), you can restart the run from scratch or continue this run.\nTo continue this run, you can use: `trainer = TorchTrainer.restore(\"C:/Users/white/ray_results/TorchTrainer_2025-01-02_00-34-29\")`.\nTo start a new run that will retry on training failures, set `train.RunConfig(failure_config=train.FailureConfig(max_failures))` in the Trainer's `run_config` with `max_failures > 0`, or `max_failures = -1` for unlimited retries."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ray\n",
    "import psutil\n",
    "import torch\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air import ScalingConfig\n",
    "\n",
    "# Initialize Ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# Define the training function\n",
    "@ray.remote\n",
    "def train_fn(config):\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "    # Simulate data size\n",
    "    data_size = config[\"data_size\"]\n",
    "    batch_size = config.get(\"batch_size\", 64)\n",
    "\n",
    "    # Generate synthetic data (X: features, y: labels)\n",
    "    X = torch.randn(data_size, 10)  # 10 features\n",
    "    y = torch.randint(0, 2, (data_size,))\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(10, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 2)  # Output layer for 2 classes\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training loop (5 epochs for better evaluation)\n",
    "    epochs = 5\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return {\"final_loss\": total_loss}\n",
    "\n",
    "# Dataset size for testing scalability (starting with smaller size)\n",
    "datasets = [10_000, 50_000]  # Simulate larger dataset sizes for better scaling evaluation\n",
    "\n",
    "# Varying number of workers (GPUs/Nodes)\n",
    "num_workers_list = [1, 2, 4, 8]  # Number of workers to simulate scaling\n",
    "\n",
    "# Loop through datasets and train with different numbers of workers\n",
    "for size in datasets:\n",
    "    for num_workers in num_workers_list:\n",
    "        start_time = time.time()\n",
    "        start_memory = psutil.Process().memory_info().rss  # Track memory before training\n",
    "\n",
    "        # Configure the trainer (Using varying number of workers)\n",
    "        trainer = TorchTrainer(\n",
    "            train_loop_per_worker=train_fn,\n",
    "            scaling_config=ScalingConfig(num_workers=num_workers),\n",
    "            train_loop_config={\"data_size\": size}\n",
    "        )\n",
    "\n",
    "        # Train and get results\n",
    "        results = trainer.fit()\n",
    "\n",
    "        end_time = time.time()\n",
    "        end_memory = psutil.Process().memory_info().rss  # Track memory after training\n",
    "\n",
    "        training_time = end_time - start_time\n",
    "        memory_usage = (end_memory - start_memory) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "        print(f\"Dataset size: {size}, Workers: {num_workers}, Training time: {training_time:.2f} seconds, Memory usage: {memory_usage:.2f} MB\")\n",
    "\n",
    "        # Optional: Measure GPU utilization\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_usage = torch.cuda.memory_allocated() / (1024 ** 2)  # MB\n",
    "            print(f\"GPU memory used: {gpu_usage:.2f} MB\")\n",
    "\n",
    "# Shut down Ray\n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db69970-2b1a-4994-ab6b-e0366585202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\white\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7fe8bd2-d528-4f32-bca7-8ad39877adde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Untitled2.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f6e704e-a180-4a84-bb35-1ceae2ec689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\tmodified:   Untitled2.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "053c7bdc-f8c9-4137-8180-c4e5d744e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global core.autocrlf true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7035198-1358-4c70-bfd8-c81a224ceac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae8a01fc-2c3b-48ee-8601-6f0a9f8b2b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\tmodified:   Untitled2.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48587b4d-5b65-4e9b-b777-204840002c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Untitled2.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3487222-2e81-4838-b1ef-c46ba2eafad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main ce4c94b] Updated training with more memory usage\n",
      " 1 file changed, 264 insertions(+), 182 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Updated training with more memory usage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99e8b3c1-3057-4a01-9666-9716b2f8f2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/whitemr7/Ray.git\n",
      "   eec3054..ce4c94b  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git push origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e32d978-2f31-437b-9aeb-5b3f6f27331d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
